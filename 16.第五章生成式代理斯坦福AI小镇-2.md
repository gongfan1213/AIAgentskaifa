### AI Agent应用与项目实战

Eddy：早上好，爸爸。我睡得很好。

John：那很好。你正在做什么？

Eddy：我正在为我的课创作一首新的音乐作品。这周就要提交了，所以我正在努力完成它，但我真的很享受这个过程！

John：听起来很棒！

Eddy出门后不久，Mei起床来到John身边坐下。Mei询问了它的儿子，John和Eddy的对话如下。

Mei：Eddy已经去学校了吗？

John：是的，它刚走。它正在为它的课创作音乐作品。

Mei：哦，那太好了！给我详细讲讲。

John：我觉得它很喜欢这个。它说它很享受这个过程。

Mei：那太好了！我为它感到骄傲。

当它们结束对话后，Mei和John收拾行装。Mei继续去教课和撰写它的研究论文，而John在上午9:00前打开斯坦福AI小镇药房的柜台开始工作。



#### 5.4.4 自发社会行为

通过彼此互动，斯坦福AI小镇中的生成式代理相互交换信息，形成新的关系并协调联合活动。这些社会行为是自发的，而不是预先编程的。

1. **信息传播**

当代理们注意到彼此，它们可能会进行对话——在这个过程中，信息可以从一个代理传播到另一个代理。例如，在Sam和Tom之间的对话中，Sam告诉Tom，它正在参加当地选举。

Sam：嘿，Tom，最近怎么样？

Tom：很好，谢谢。怎么了？

Sam：嗯，我想和你谈一些事情。实际上，我正在参加即将到来的当地选举。

Tom：真的吗？那太好了！你为什么要参选？

Sam：我多年来一直想参与当地政治，我真的觉得我可以在研究团队中产生影响。另外，我想带来新的想法和观点。

### 第5章 生成式代理——以斯坦福AI小镇为例

2. **关系记忆**

斯坦福AI小镇中的生成式代理之间随着时间的推移形成新的关系，并记住彼此的互动。例如，在开始时，Sam不认识Latoya Williams。在Johnson Park散步时，Sam偶然遇到Latoya，它们互相介绍。Latoya提到它正在制作一个摄影项目：“我在这里为一个我正在进行的项目拍照。”在之后Sam与Latoya的互动中表明它记得上次的互动，因为它问：“嗨，Latoya，你的项目进展得如何？”Latoya回答：“嗨，Sam，进展顺利！”

3. **协调沟通**


生成式代理之间可以相互协调沟通。Isabella在Hobbs Cafe计划一个2月14日下午5:00 - 7:00的情人节派对。从这个意图开始，生成式代理在Hobbs Cafe或其他地方看到朋友和顾客时，就邀请它们参加派对。Isabella在派对的前一天下午装饰咖啡馆。Maria是Isabella的常客和密友，它来到咖啡馆。Isabella请求Maria帮助它为派对做装饰，Maria同意了。Maria的角色描述提到它对Klaus有好感。那天晚上，Maria邀请它暗恋的对象Klaus参加派对，Klaus欣然接受。

在情人节当天，包括Klaus和Maria在内的五位代理，在下午5:00出现在Hobbs Cafe举行庆祝活动。如图5 - 14所示，在这个场景中，最终用户只设置了Isabella举办派对的初始意图和Maria对Klaus的暗恋。传播消息、装饰、相互邀请、参加派对，以及在派对上互动的社会行为都是由生成式代理架构发起的。



![image](https://github.com/user-attachments/assets/a8978234-4c8a-41d4-a8ac-80bf05d13383)




#### 5.5 生成式代理架构

生成式代理旨在为开放世界提供一个行为框架：一个能够与其他代理进行交互并对环境变化做出反应的框架。生成式代理将当前环境和过去的经历作为输入，并生成行为输出。在这种行为背后是一种新颖的代理架构，它结合了一个大语言模型和用于行为检索相关信息以调节大语言模型输出的机制。如果没有这些机制，那么大语言模型综合与行为，但生成的代理可能不会根据代理的过去经历做出反应，也可能不会做出重要的推理，并且可能无法保持长期连贯性。即使在使用当今十分强大的模型（如GPT - 4）时，长期规划和连贯性的挑战也依然存在。由于生成式代理会产生大量必须保留的大型事件和记忆流，因此架构设计的一个核心挑战是确保在需要时检索并综合代理记忆中最相关的部分。

架构设计的核心是记忆流，记忆流是一个数据库，用于保存代理经历的所有记录。从记忆流中检索出的记录，作为计划代理行为和适当反应环境的相关部分。记录被递归、迭代成更高级别的反思，这些反思再来指导行为。架构中的一切都被记录并作为自然语言描述进行推理，从而使架构能够利用大语言模型。

该项目当前的实现使用了ChatGPT的gpt3.5 - turbo版本，研究团队期望生成式代理的记忆、计划和反思这三元架构能够在大语言模型改进时保持不变，更新的大语言模型（如GPT - 4）将继续提高构成生成式代理的基础的表现力和性能。

#### 5.5.1 记忆和检索

创建能够模拟人类行为的生成式代理需要对远大于提示中应描述的一系列经历进行推理，因为完整的记忆流可能会分散模型的注意力，甚至目前无法适应有限的上下文窗口。考虑这样一个场景，Isabella被问道：“你最近热衷于什么？”如果将Isabella的所有经历总结以适应大语言模型的有限上下文窗口，将产生一个信息量很少的答案，其中Isabella讨论了合作事件、项目和对咖啡馆的清洁和组织活动。相反，下面描述的记忆流会突出相关记忆，从而产生更有信息量和具体的回应，提到：Isabella热衷于让人们感到受欢迎和包容，策划活动并创造人们可以享受的氛围，如情人节派对。

为解决类似问题，可通过引入记忆流来维护代理经历的全面记录。它是一个记忆对象列表，每个对象包含自然语言描述、创建时间戳和最近访问时间戳。记忆流的最基本元素是观察，这是代理直接感知的事件。常见的观察包括代理自己执行的行为，或者代理感知到其他代理或非代理对象执行的行为。例如，在Hobbs Cafe工作的Isabella可能随着时间的推移积累了以下观察：①Isabella正在摆放糕点，②Maria Lopez一边喝着咖啡一边为应对化学测试学习，③Isabella和Maria正在讨论在Hobbs Cafe策划情人节派对的事情，④冰箱空了。

生成式代理架构实现了一个检索功能，它将代理当前的情况作为输入，并返回要传递给大语言模型的记忆流的一个子集。根据代理决定如何行动时需要考虑的内容，有许多可能的检索功能实现方式，如图5 - 15所示。



![image](https://github.com/user-attachments/assets/9a2e8e7b-aab9-4f7d-a695-f37eaa885a4e)


在这样的上下文中，研究团队专注于三个要素，即最近性（recency）、重要性（importance）和相关性（relevance），这些要素共同产生有效的结果。

最近性为最近访问过的记忆对象赋予更高的分数，这样一来，片刻前或今天早上发生的事件很可能仍然在代理的注意力范围内。在实现中，研究团队将最近性视为自上次检索记忆以来沙盒游戏小时数的指数衰减函数，衰减因子是0.995。

重要性通过为代理认为重要的记忆对象赋予更高的分数来区分平凡和核心记忆。例如，像在房间里吃早餐这样的平凡事件会产生较低的重要性分数，而与重要的另一半分手会产生较高的重要性分数。重要性分数有许多可能的实现方式，研究团队发现直接要求大语言模型输出一个整数分数是有效的，完整的提示如下。

在1 - 10分的评分标准中，1分表示纯粹平凡（如刷牙、铺床），10分表示极其深刻（如分手、被大学录取），请评估下面这段记忆可能的深刻程度。

记忆：在Willows Market and Pharmacy购买杂货。


评分：<填写>。

这个提示对于“打扫房间”返回了一个整数值2，对于“向暗恋对象表白”返回了一个整数值8。重要性分数是在创建记忆对象时生成的。

相关性为与当前情况相关的记忆对象赋予更高的分数。什么是相关的取决于“与什么相关”，因此研究团队将相关性限定在一个查询记忆上。如果查询是一个学生正在与同学讨论为应对化学测试应该学习什么，那么关于它们早餐的记忆对象的相关性应该很低，而关于老师和学校作业的记忆对象的相关性应该很高。在研究团队的实现中，研究团队首先使用大语言模型为每个记忆的文本描述生成一个嵌入向量。然后研究团队计算相关性，将其作为记忆的嵌入向量与查询记忆的嵌入向量之间的余弦相似度。

为了计算最终的检索分数，研究团队使用最小 - 最大缩放将最近性、相关性和重要性分数归一化到[0,1]范围内。检索功能将三个要素的加权组合作为所有记忆的分数：

Score_retrieval = W_recency·Score_recency + W_relevance·Score_relevance + W_importance·Score_importance

在研究团队的实现中，将所有的权重都设置为1。大语言模型上下文窗口内排名最高的记忆被包含在提示中。

#### 5.5.2 反思

当只配备原始观察记忆时，生成式代理在进行概括或推断时存在困难。考虑这样一个场景，Klaus被用户问道：“如果你必须选择一个你认识的人一起度过1小时，你会选择谁？”仅凭观察记忆，Klaus简单地选择了与它互动最频繁的人——Wolfgang Schulz（它的大学宿舍邻居），然而Wolfgang和Klaus只见过面，并没有进行过深入互动。更理想的回应要求代理从Klaus花费数小时进行项目研究的记忆中概括出Klaus对研究的热情，并且同样认识到Maria在自己的领域内也在努力（尽管领域不同），从而产生一个反思，它们有共同的兴趣。

为解决类似问题，研究团队引入了第二种类型的记忆，将其称为反思。反思是由生成式代理生成的更高层次、更抽象的想法。因为反思是记忆的一种类型，所以当检索发生时，它会与其他观察一起被包含。反思是定期生成的，在研究团队的实现中，当代理感知到的最新事件的重要性分数之和超过一个阈值时（在研究团队的实现中是150），研究团队生成反思。实际上，研究团队的代理每天反思两三次。层次化的反思图如图5 - 16所示。

反思的第一步是代理确定要反思什么，通过识别根据代理最近的经历提出问题。研究团队使用100条代理记忆流中的最新记录查询大语言模型（例如，“Klaus正在阅读有关绅士化的书”“Klaus正在与图书管理员讨论它的研究项目”“图书馆的桌子目前无人占用”），并提示大语言模型：“仅根据上面的信息，研究团队可以回答哪3个最突出的高层次问题？”

通过模型的响应生成候选问题，例如，Klaus对什么主题充满热情？Klaus和Maria之间是什么关系？首先研究团队使用这些问题进行检索查询，并为每个问题收集相关记忆（包括其他反思）。然后研究团队提示大语言模型提取见解，并引用作为见解证据的特定记录。完整的提示如下。


![image](https://github.com/user-attachments/assets/10d213c3-234c-41ec-a2c2-e38291f514b3)



关于Klaus的陈述：

1. Klaus正在写一篇研究论文；

2. Klaus喜欢阅读有关绅士化的书；

3. Klaus正在与Ayesha Khan讨论锻炼[……]。


从上述陈述中，你能推断出5个高级别的见解吗？

这个过程生成了这样的陈述：Klaus致力于它的绅士化研究。研究团队解析并存储这个陈述作为记忆流中的反思，包括指向被引用的记忆对象的指针。

反思明确允许代理不仅反思它们的观察，还反思其他的反思。例如，上述关于Klaus的第二条陈述是一个反思，这是Klaus之前就有的，而不是来自它对环境的观察。结果，代理生成了反思树：树的树叶节点代表基础观察，非叶节点代表思想，越往上树的层级越高，思想就越抽象，思想的层次就越高。


#### 5.5.3 计划和反应

虽然大语言模型可以针对情景信息生成看似合理的行为，但生成式代理需要在一个较长的时间范围内进行计划，以确保它们的行动序列是连贯和可信的。如果研究团队用Klaus的背景提示大语言模型，描述时间，并询问它在给定时刻应该采取什么行动，那么Klaus可能在中午12:00吃午餐，并在中午12:30和下午1:00再次吃午餐，尽管它已经吃过午餐了。优化当前时刻的可信度牺牲了随着时间推移的可信度。为了克服这个问题，设置计划是必需的。采用下面描述的方法，Klaus的下午计划就不那么贪吃了：中午12:00它在Hobbs Cafe吃午餐并阅读，下午1:00在学校图书馆工作，撰写研究论文，下午3:00休息散步。

为解决类似问题，研究团队引入了计划，计划描述了生成式代理未来的一系列行动，并帮助代理保持其行为随时间一致。一个计划包括地点、开始时间和持续时间。例如，Klaus致力于它的研究并且有一个即将到来的截止日期，它可能选择花一天时间在桌子上工作，撰写研究论文。计划的一个条目可能会声明如下：从2023年2月12日上午9:00开始，持续180分钟，在橡树山学院的宿舍楼Klaus的房间的书桌旁，阅读并做研究论文笔记。与反思一样，计划也存储在记忆流中，并包含在检索过程中。这使得代理在决定如何行动时可以一起考虑观察、反思和计划。代理在必要时可以中途更改它的计划。

让一名艺术家代理在药房柜台前坐着画4小时的画而不动，这既不现实也无趣。一个更理想的计划是，让艺术家代理在其家庭工作室中花时间收集材料、混合颜料、休息并在4小时内清理干净。为了创建这样的计划，研究团队提供的方法是从上到下，递归地生成更多细节。第一步是创建一个概述计划，研究团队会向大语言模型提供代理的概要描述（如名字、特征及其最近经历的概要）和对它前一天的总结，以下是一个完整的示例提示，提示的底部未完成，供大语言模型完成。

姓名：Eddy Lin（年龄：19岁）。

固有特征：友好、外向、好客。

Eddy是在橡树山学院学习音乐理论和作曲的学生。Eddy喜欢探索不同的音乐风格，并且总是在寻找扩展知识的方法。Eddy正在为它的大学班级创作一首音乐作品。它正在上课学习更多的音乐理论。Eddy对它正在创作的新作品感到兴奋，但它希望在接下来的几天里能投入更多的时间来进行创作。

2月12日星期二，Eddy①早上7:00醒来并完成了早上的例行公事……⑥大约晚上10:00准备睡觉。

今天是2月13日星期三，这是Eddy一天大致的计划：①……

下面为代理一天的计划提供了一个粗略的草图，分为五到八块：①早上8:00醒来并完成早上的例行公事，②上午10:00去橡树山学院上课……⑤下午1:00 - 5:00创作它的音乐作品，⑥下午5:30吃晚餐，⑦完成学校作业并在晚上11:00前上床睡觉。

代理将此计划保存到记忆流中，并递归分解它以创建更细致的动作，首先是按小时划分的行动块——Eddy计划从下午1:00 - 5:00创作它的音乐作品，分解为下午1:00开始为它创作的音乐作品进行头脑风暴……下午4:00稍作休息，补充创作能量，然后回顾和完善它的作品。接下来，我们再次将其递归分解为5 - 15分钟的行动块。例如，下午4:00吃一份轻食，如一块水果、一个麦片棒或一些坚果，下午4:05在它的工作区周围散步……下午4:50花几分钟时间清理它的工作区。此过程可以根据所需的粒度进行调整。

1. **反应和更新计划**

生成式代理在一个行动循环中运行，它们在每个时间段感知周围的世界，并将这些感知的观察存储在它们的记忆流中。研究团队提示大语言模型根据这些观察来决定生成式代理是否应继续它们现有的计划或做出反应，如站在画架前绘画可能会触发对画架的观察，但这不太可能引发反应。然而，如果Eddy的父亲John看到Eddy在家里的花园里散步，结果就会不同。提示如下，[生成式代理的总结描述]代表动态生成的、段落长的代理总体目标和性格的总结。

[生成式代理的总结描述]

现在是2023年2月13日，下午4:56。

John的状态：John今天早些时候从工作场所回来。

观察：John看到Eddy在工作场所周围散步。

来自John记忆的相关上下文摘要：Eddy是John的儿子。Eddy一直在为它的班级创作音乐作品。Eddy喜欢在思考或听音乐时在花园里散步。John考虑询问Eddy关于它创作的音乐作品。

如果是这样，那么John应该如何做出适当的反应呢？

上下文摘要是通过两个提示生成的，这些提示通过查询“[观察者]与[被观察实体]的关系是什么”和“[被观察实体]是[被观察实体的动作状态]”，将它们的答案总结在一起。输出建议John可以考虑询问Eddy关于它创作的音乐作品。然后研究团队重新更新生成式代理的现有计划，从反应发生的时间开始。最后，如果动作表明生成式代理之间的交互，那么研究团队生成它们的对话。

2. **对话**

生成式代理在互动时会进行对话。研究团队基于它们对彼此的记忆来生成代理的话语。例如，当John开始与Eddy对话时，通过使用John对Eddy的总结


记忆和当John决定询问Eddy关于它创作的曲子时的预期反应来生成John的第一句话：

[生成式代理的摘要描述]

现在是2023年2月13日，下午4:56。

John的状态：John今天早些时候从工作场所回来。

观察：John看到Eddy在工作场所周围散步。

来自John记忆的相关上下文摘要：Eddy是John的儿子。Eddy一直在为它的班级创作音乐作品。Eddy喜欢在思考或听音乐时在花园里散步。John正在询问Eddy关于它创作的音乐作品。John会对Eddy说什么？

结果：“嘿，Eddy，你为班级创作的音乐作品的进展如何？”

从Eddy的角度来看，John发起对话被视为自己可能想要做出反应的事件。因此，就像John一样，Eddy检索并总结了它对与John的关系的记忆，以及可能与John对话中最后一句话相关的记忆。如果Eddy决定回应，那么研究团队使用它的总结记忆和当前的对话历史来生成Eddy的话语：

[生成式代理的摘要描述]

现在是2023年2月13日，下午4:56。

Eddy的状态：Eddy正在它的工作场所周围散步。

观察：John正在与Eddy对话。

来自Eddy记忆的相关上下文摘要：John是Eddy的父亲。John很关心，并且有兴趣了解更多关于Eddy在学校的工作。John知道Eddy正在创作音乐作品。下面是对话历史。

John：嘿，Eddy，你为班级创作的音乐作品的进展如何？Eddy会如何回应John？

这产生了Eddy的回应：“嘿，爸爸，进展顺利。我一直在花园里散步，梳理我的思路，获得一些灵感。”这个对话持续使用相同的机制，直到其中一个代理决定结束对话。



#### 5.6 沙盒环境实现

斯坦福AI小镇沙盒环境是使用Phaser网络游戏开发框架构建的，将包括生成式代理头像在内的视觉环境元素，以及制作的环境地图和碰撞地图，均导入Phaser中。

通过一台服务器来补充沙盒开发框架，使沙盒信息对生成式代理可用，并使生成式代理能够移动和影响沙盒环境。该服务器维护一个JSON数据结构，包含沙盒世界中每个生成式代理的信息（它们的当前位置、当前行为的描述以及它们正在互动的沙盒对象）。在每个沙盒时间步，沙盒服务器解析来自生成式代理的JSON数据，更新生成式代理的位置，并更新生成式代理正在互动的沙盒对象的状态（例如，如果生成式代理的动作是“为Hobbs Cafe的顾客制作浓缩咖啡：柜台：咖啡机”，则咖啡机的状态会从“闲置”变为“正在煮咖啡”）。沙盒服务器还负责将每个生成式代理的预设视觉范围内的所有代理和对象发送到该代理的记忆中，以便生成式代理可以适当地做出反应。生成式代理的输出动作随后更新JSON数据，整个过程为下一个时间步循环。

最终用户通过简短的自然语言描述初始化一个新生成式代理，如关于John的段落中所述。在实现中，将这个用分号分隔的特征列表拆分成一组记忆。这些记忆作为初始记忆，用于决定生成式代理的行动。这些记忆是初始的起点；随着生成式代理在沙盒世界中获得更多经验，并且更多的记录充满记忆流，生成式代理的总结和行动将会逐渐演变。

生成式代理的架构使用自然语言进行操作。因此，需要使用一种机制将生成式代理的推理与沙盒世界联系起来。为此，将沙盒环境（包括区域和对象）表示为树形数据结构，树中的边（父子节点间的连接）表示沙盒世界中的包含关系。我们将这棵树转换成自然语言，以传递给生成式代理。例如，“炉子”作为“厨房”的子节点被转换为“厨房里有一个炉子”。

生成式代理在导航环境时构建环境的个体树表示，即整体沙盒环境树的子图。用一个环境树初始化每个生成式代理，该树用于捕捉生成式代理应该意识到的空间和对象：它们的居住区、工作场所及经常光顾的商店。随着生成式代理在沙盒环境中导航，它们会更新这棵树，以反映新感知到的区域。生成式代理并非无所不知，当它们离开一个区域时，它们的树可能会变得过时，并在重新进入该区域时进行更新。

为了确定每个动作的合适位置，我们会遍历生成式代理存储的环境树，并将其一部分转化成自然语言，以提示大语言模型。从生成式代理环境树的根节点开始递归，提示大语言模型找到最合适的区域。例如，如果Eddy的生成式代理指示它应该在工作场所周围散步：

[生成式代理的摘要描述]

Eddy目前在Lin家族的房子中：Eddy的卧室：桌子，其中包括Mei和John的卧室、Eddy的卧室、公共区域、厨房、浴室和花园。

Eddy知道以下区域：Lin家族的房子、Johnson Park、Harvey Oak Supply Store、Willows 



