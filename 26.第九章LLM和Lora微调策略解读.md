### 第 9 章 LLM 与 LoRA 微调策略解读
在当今快速发展的 AI 领域中，LLM 已成为各种任务的核心，在自然语言处理、文本生成、语言理解等领域中展现出惊人的潜力。然而，要让这些模型在特定任务上表现得更加出色，通常需要进行微调以使其适应特定领域或数据集。微调技术的重要性不言而喻，通过微调策略可以根据特定任务或领域的需求调整预训练模型的参数，提升模型在特定领域中的性能和泛化能力。然而，传统的微调策略往往面临着计算成本高昂的挑战，尤其是对 LLM 而言。LoRA 技术的出现提供了解决方案，其高效的特性大大降低了微调的计算成本，同时保持了模型的性能和泛化能力。LoRA 技术的出现不仅解决了传统微调策略的计算成本问题，还为研究人员和从业者提供了一个更加高效和实用的微调策略。

#### 9.1 LoRA 技术
##### 9.1.1 LoRA 简介

LoRA 是一种可用于更高效地微调 LLM 的流行技术。相比传统的微调策略，LoRA 不需要调整深度神经网络的所有参数，仅需更新一小部分低秩矩阵即可。

LoRA 与其他常见的微调策略相比，具有以下优势。

- **计算效率高**：LoRA 通过低秩矩阵分解，降低了模型参数的更新成本，从而提高了微调过程的计算效率。

- **减少内存占用量**：LoRA 减少了需要存储和更新的参数量，因此可以减少内存占用量，并且在推理时不会大大增加计算、内存等的负担。

- **灵活性强**：LoRA 可以灵活地应用于各种不同的模型架构和任务中，为模型优化提供了一种通用的方法。

全参数微调、Adapter、P - Tuning 和 Prefix 等微调策略虽然也可以实现模型的微调，但其在计算效率和灵活性方面存在一定的局限性。因此，针对 LLM 微调的场景，LoRA 往往是一种更优的选择。

|微调策略|优点|缺点|原理|
| ---- | ---- | ---- | ---- |
|全参数微调|简单直接，易于实现。可以适应任何任务，没有额外的参数|需要占用大量的计算资源和时间，尤其是对 LLM 而言。在微调过程中可能会出现过拟合的问题|全参数微调是指在微调过程中，更新整个预训练模型的所有参数，包括权重和偏置|
|Adapter|相比全参数微调，Adapter 需要的参数量较少，节省了内存和计算资源。可以在不同层次的模型中插入适配器，灵活性较高|可能需要通过进行额外的调优来确定适配器的位置和数量。在某些情况下，适配器可能会影响模型的性能|Adapter 是一种轻量级的神经网络结构，用于在预训练模型的某些层上进行微调，而保持其他层的参数不变|
|P - Tuning|可以在不同任务之间共享部分参数，提高了参数的复用性。可以通过调整参数共享的程度来平衡不同任务之间的关系|需要通过精细调参来确定参数共享的方式和程度。可能会出现任务之间干扰的问题，从而影响模型性能|P - Tuning 是一种参数共享的微调策略，通过在多个任务之间共享参数来提高模型的泛化能力和效率|
|Prefix|可以通过添加特定的前缀来改变模型的行为，增强了模型的适应性。可以针对不同的任务设计不同的前缀，提高了模型的灵活性|需要通过执行额外的设计工作来确定合适的前缀。前缀的设计可能会影响模型的性能|Prefix 是一种通过在输入数据中添加特定的前缀来控制模型行为的微调策略，可以使模型适应不同的任务或输入|
|LoRA|高效利用了模型的灵活性，参数量和内存占用量，降低了计算成本。保持原始模型的结构不变，只更新特殊的 LoRA 权重，避免了过拟合的问题|由于 LoRA 只更新了部分参数，因此可能会导致模型在某些方面的能力下降。例如，在数学上的计算能力|LoRA 适用于 LLM 的微调场景，特别是在计算资源和时间有限的情况下，它能够提供高效的解决方案。由于 LoRA 在微调过程中保持了模型的整体结构，因此可以应用于各种文本处理任务，如文本生成、文本分类等|

##### 9.1.2 LoRA 工作原理

LoRA 的工作原理基于低秩矩阵的概念，通过将权重更新近似为低秩的方式来实现微调。具体而言，当需要在微调过程中更新模型参数时，传统微调策略会计算一个完整的权重更新矩阵 ΔW，而在 LoRA 中，将这个权重更新矩阵 ΔW 分解成两个较小的矩阵 \( W_A \) 和 \( W_B \) 的乘积，即 \( \Delta W \approx W_A \times W_B \)。

这种分解可以简化参数的更新过程，并显著降低计算成本。在实践中，可以将权重更新矩阵 ΔW 分解为两个低秩矩阵 \( W_A \) 和 \( W_B \)，并将更新表示为 \( W' = W + W_A \times W_B \)。这样，只需要学习两个较小的矩阵 \( W_A \) 和 \( W_B \)，而不必更新整个模型的参数。下图所示为传统微调策略（左）和 LoRA（右）在前向传递过程中权重更新的对比。

![image](https://github.com/user-attachments/assets/a62f369b-ef2b-40c1-a820-f5d3560b810e)

![image](https://github.com/user-attachments/assets/29d29443-f8eb-475c-8e9b-5dfdad83a6a1)


具体而言，可选择一个低秩超参数 r 来指定适应的低秩矩阵的秩。通过选择较小的 r 值，低秩矩阵变得更简单，需要学习的参数也就更少。这样可以加快训练速度并降低计算要求。然而，随着 r 值的减小，低秩矩阵捕捉特定任务信息的能力也会下降。

例如，假设有一个大小为 2000×10000 的权重矩阵 W（共有 2000 万个参数）。如果选择 r = 8，则可以初始化两个较小的矩阵：一个大小为 2000×8 的矩阵 \( W_B \) 和一个大小为 8×10000 的矩阵 \( W_A \)。通过将 \( W_A \) 和 \( W_B \) 相加，则只需要 80000 + 16000 = 96000 个参数，比传统微调策略中的 2000 万个参数少了约 200 倍。

此外，在实践中，更重要的是尝试使用不同的 r 值，以找到适当的平衡点，从而使模型在新任务中获得理想的性能。



##### 9.1.3 LoRA 在 LLM 中的应用

目前，几乎所有的 LLM 都采用了 Transformer 作为其基础架构进行训练和优化。LoRA 作为 LLM 中广泛应用的微调策略，其主要作用于 LLM 网络结构中 Transformer 的注意力机制。LoRA 可以帮助开发人员在已经训练好的 Transformer 模型的基础上，进一步调整模型，使其更适合特定的任务。

Transformer 是一种用于处理文本数据的神经网络架构，可以帮助计算机理解语言并执行各种任务，比如翻译文本、生成对话或者预测下一个词语是什么。Transformer 之所以强大，是因为它的注意力机制可以很好地捕捉文本中词语之间的关系，从而更准确地理解文本的含义。



##### 9.1.4 实施方案

要将 LoRA 应用于 Transformer 微调，需要按照以下方案进行。

1. **加载预训练模型**：加载基于 Transformer 的 LLM，作为微调的基础模型。

2. **初始化 LoRA 权重**：初始化 LoRA 所需的一些特殊权重。

3. **定义 LoRA 前向传播函数**：在 LoRA 的前向传播函数中，首先将原始模型的输出与 LoRA 引入的低秩矩阵相乘，并乘以一个缩放因子 α，然后计算其更新部分，最后将该更新部分与原始模型输出相加，从而实现对模型参数的更新。

4. **微调过程**：在微调过程中，冻结原始模型的权重，只更新 LoRA 所需的低秩矩阵权重，以适应特定任务的需求。

在微调过程中，注意选择合适的缩放因子 α 和低秩超参数 r，以达到平衡模型性能和计算效率的目标。


#### 9.2 LoRA 参数说明
在本章中，我们选择基础模型（Qwen）作为研究对象，下面对 LoRA 涉及的相关参数进行说明。

![image](https://github.com/user-attachments/assets/fd077d1b-6cc5-4e1a-b16b-89518ccd8d12)


![image](https://github.com/user-attachments/assets/41fca9be-712c-41d0-a22a-f7a7709e539d)



##### 9.2.1 注意力机制中的 LoRA 参数选择

在调整 LoRA 微调参数时，首先需要了解应将 LoRA 插入到网络的哪些位置。在通常情况下，LoRA 仅被添加到自注意力层的 Q、K、V 和 O 矩阵中，而在其他位置（如 MLP 等位置）则未被添加。一些实验结果表明，仅将 LoRA 添加到 Q 和 V 矩阵中可能会获得更好的性能。

在论文 *LoRa: Low - Rank Adaptation of Large Language Models* 中，作者使用 LoRA 的方式分别对 Q、K、V 和 O 矩阵及其组合在数据集“WikiSQL”和“MultiNLI”上进行了验证，验证结果如下所示，其中“Weight Type”代表 Q、K、V、O 矩阵的组合方式，r 代表微调的秩。

通过对比可见，使用“\( W_q \)，\( W_k \)，\( W_v \)，\( W_o \)”组合时的效果最好，“\( W_q \)，\( W_v \)”组合的效果略差。但在计算参数的数量上，“\( W_q \)，\( W_v \)”比“\( W_q \)，\( W_k \)，\( W_v \)，\( W_o \)”少一半，因此更推荐使用“\( W_q \)，\( W_v \)”的参数组合方式。


##### 9.2.2 LoRA 网络结构中的参数选择

LoRA 网络结构中参数的选择至关重要。其中，低秩超参数 r 和缩放因子 α 的选择直接影响了计算量和微调的最终性能。

LoRA 超参数调整对比如下。

下面通过引用第三方的测试结果，深入讨论如何选择和调整 LoRA 中的关键参数，以观察并实现最佳的微调效果。在 LoRA 低秩超参数调整过程中，第三方数据主要关注了低秩超参数 r 和缩放因子 α 的影响。

- **改变低秩超参数 r**：
-
- r 是 LoRA 中关键的参数之一，决定了 LoRA 矩阵的秩或维度，直接影响了模型的复杂性和容量。较大的 r 值表示更强的表现力，但也可能会导致过拟合，而较小的 r 值则可能会牺牲表现力以减少过拟合的风险。在本实验中，将保持所有层都启用 LoRA，并将 r 值从 8 增加到 16，以便观察其对模型性能的影响。结果显示，只增加 r 值会导致模型性能下降。


![image](https://github.com/user-attachments/assets/601c5850-a8bc-4d58-86a8-3e3204c81ca0)


- **改变缩放因子 α**：
-
-
- 在本实验中对缩放因子 α 进行调整，并观察其对模型性能的影响。通过实验，发现将 α 增加到一定阈值可以改善模型性能，但一旦超过一定阈值，模型性能就会下降。调整 α 有助于在数据拟合和模型正则化之间找到平衡。一般来说，在微调 LLM 时，倾向于选择一个比 r 值大两倍的 α 值（请注意，这与使用扩散模型时有所不同）。正如下图所示，当将 α 值设置为 r 值的两倍，且 α 值增加到 32 时表现出了最佳的模型性能。


![image](https://github.com/user-attachments/assets/d3c0f40c-ab64-4fb9-8c89-e4fff26ef203)


- **设置超大参数 r**：
-
-
-
- 选用较大的 r 值，在模型性能提升方面并不明显。通常建议将 α 值设置为 r 值的两倍，例如，r = 256 和 α = 512，这好像能够带来最佳的模型性能，而较小的 α 值则可能导致较差的模型性能。然而，如果让 α 值超过 r 值的两倍，则可能会使基准效果变得更差。



![image](https://github.com/user-attachments/assets/382cc90d-5ad5-42fd-8483-4fba105ec5a2)


以上探讨了如何平衡 LoRA 的关键参数 r 和 α，以获得最佳的模型性能。选择合适的 r 值和 α 值对于提升模型性能至关重要，开发人员需要根据具体情况进行调整。

##### 9.2.3 LoRA 微调中基础模型的参数选择

当前，Qwen 基础模型的参数规模分别为 0.5B、1.8B、4B、7B、14B、32B、72B、110B，其中，B 表示 10 亿，7B 基础模型的大小约为 15.45GB，14B 约为 28.34GB，72B 约为 147GB。选择较小规模的基础模型会占用较少的显存，对显存配置的要求较低，但微调后的模型性能会相对较差；而选择较大规模的基础模型则会占用更多显存，对显存配置的要求更高，但微调后的模型性能会更好。

基础模型微调的精度包括 Float32、Float16、Int8、Int4。其中，Float32 占用 4 字节，Float16 占用 2 字节，Int8 占用 1 字节，Int4 占用 0.5 字节。选择更低的精度会导致微调精度损失增加，但显存和计算资源的占用量会减少。在 LoRA 微调中，通常会选择使用 Float16 精度进行微调。

在实际项目中，基础模型大小和精度的选择应根据设备具体情况来确定。


#### 9.3 LoRA 扩展技术介绍
##### 9.3.1 QLoRA 介绍
QLoRA 是一种高效的微调策略，通过引入 4 位 NormalFloat（NF4）数据类型和量化技术，在保持精度的前提下大幅减少内存占用量，不会影响模型性能。它首先将模型量化为 4 位，然后按照 LoRA 的方式对模型进行微调。可以说，QLoRA 继承了 LoRA 的框架和理念，同时充分利用了量化技术的优势，进一步提升了模型的性能和计算效率。LoRA 和 QLoRA 的对比如下图所示。


![image](https://github.com/user-attachments/assets/eb740be5-29f8-40e7-8dbe-2b81071e92fc)


##### 9.3.2 Chain of LoRA 方法介绍

尽管 LoRA 在微调 LLM 方面具有显著优势，但在泛化误差方面仍不及全参数微调。利用 Chain of LoRA（COLA）方法，可以在保持计算效率的同时减小 LoRA 与全参数微调之间的泛化误差。

Chain of LoRA 采用残差学习方法，通过迭代微调，将学习到的 LoRA 模块合并到预训练的 LLM 参数中，构建 LoRA 链，以此逼近全参数微调的效果，其结构如下图所示。


![image](https://github.com/user-attachments/assets/45ad9229-b6cf-4d26-98e5-08600833825d)


#### 9.4 LLM 在 LoRA 微调中的性能分享
首先，微调需要选择开源的 LLM，以便将 LoRA 集成到其网络结构中。

其次，在性能方面以 7B 的 Qwen 模型为例，设置 r = 8，α = 16，微调精度为 Float16 的情况下，微调参数约为原模型参数的 4.6%。在微调过程中，大约使用了 19GB 显存，可在一台 24GB 显存的设备上完成微调。在整个微调过程中，使用了 10 000 条指令数据集，进行了 100 轮次的微调，大约耗时 4 天。 
