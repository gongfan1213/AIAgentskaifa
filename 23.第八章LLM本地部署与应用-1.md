### 第8章 LLM本地部署与应用
在当今信息爆炸的时代，自然语言处理（NLP）技术已经成为连接人与机器的桥梁，使得机器能够更好地理解人类语言并给出回应。LLM作为NLP领域的一项重要技术，具有出色的文本生成、理解和对话能力，为众多应用场景提供了强大的支持。

随着深度学习（DL）技术的飞速发展，LLM的性能不断突破，但同时给模型部署带来了新的挑战。在云端部署LLM虽然便捷，但由于数据隐私、网络传输延迟及成本等方面的问题，越来越多的场景需要在本地进行模型部署。因此，掌握LLM本地部署与应用的技术，对于充分发挥LLM的能力、满足各种应用需求具有重要意义。

通过本地部署LLM，用户可以直接在本地设备上运行模型，从而避免云端部署可能带来的数据泄露风险，同时可以减少网络传输延迟，提高响应速度。此外，本地部署还可以根据实际需求对模型进行定制和优化，以满足特定的业务场景需求。

本章旨在为读者提供一份详尽且实用的LLM本地部署与应用指南。我们将从硬件基础设施的搭建开始，逐步引导读者完成整个部署流程，内容包括操作系统的合理配置、必要环境的安装与设置、LLM核心参数的介绍、模型量化技术的深入解析，以及模型选择的智慧。此外，我们还将探讨模型在各类场景中的实际应用，并通过通义千问模型的部署案例，为读者提供一次实战演练的机会。通过学习本章，希望读者能够轻松掌握LLM本地部署的技巧，从而更好地应对各种实际应用需求。

#### 8.1 硬件准备

在进行LLM本地部署时，硬件准备是非常关键的一步。由于LLM通常非常庞大，需要处理大量的数据和计算，因此选择合适的硬件设备对于确保LLM的顺畅运行至关重要。

1. **内存**：如果LLM使用GPU推理，则需要设置32GB以上的内存；如果使用CPU推理，则需要设置64GB以上的内存。

2. **CPU**：CPU需要使用Intel CPU，指令集采用x86架构，CPU核数在4核以上，处理器在i7以上。 

3. **GPU**：GPU需要使用NVIDIA GPU，显存在4GB以上（具体与部署模型的大小有关），型号使用RTX及GTX。


#### 8.2 操作系统选择

在进行LLM（通常指的是需要执行大量计算和使用大量存储资源的深度学习模型）本地部署时，选择合适的操作系统也是至关重要的一环。操作系统不仅影响到模型训练和推理的效率，还关乎系统稳定性、兼容性和安全性。以下是几种常见的操作系统，以及它们在LLM场景下的优缺点。

1. **Windows**
    - **优点**：Windows提供了直观的图形用户界面，初学者更容易上手。Windows还支持大量的硬件和软件，具有较好的兼容性。
    - **缺点**：虽然Windows支持深度学习框架，但许多先进的深度学习工具和库可能首先针对Linux发布。此外，Windows还需要使用更多的系统资源来运行，这可能会影响到模型训练和推理的效率。

2. **CentOS**
    - **优点**
        - **稳定性**：CentOS以其卓越的稳定性而闻名，特别适合服务器环境和需要长时间运行的任务，如LLM的训练和推理。 
        - **安全性**：CentOS在安全性方面表现出色，可以及时提供安全更新和修复，以确保系统免受威胁。 
        - **企业级支持**：作为Red Hat Enterprise Linux（RHEL）的开源版本，CentOS可以利用RHEL的企业级功能，这对需要具有高度可靠性和稳定性的企业级应用来说是一个重要优势。 
    - **缺点**
        - **更新速度较慢**：CentOS的软件库通常不包含最新的软件版本，这可能会限制新功能和改进功能的使用。这对需要使用最新版本深度学习框架和库的LLM来说可能是一个劣势。 
        - **社区规模较小**：与Ubuntu相比，CentOS的用户和开发社区规模较小，因此其可用的教程、指南和资源比较有限。 


3. **Ubuntu**
    - **优点**
        - **更新频繁**：Ubuntu每六个月发布一次新版本，以确保用户能够及时获得最新的软件和功能。这对需要使用最新版本深度学习框架和库的LLM来说是一个优势。 
        - **易于使用**：Ubuntu具有用户友好的界面和丰富的文档，使得初学者更容易上手。此外，Ubuntu还提供了广泛的技术支持和社区资源。 
        - **广泛的硬件支持**：Ubuntu支持广泛的硬件设备，使用户在各种不同硬件上部署LLM变得更加容易。 
    - **缺点**
        - **稳定性**：由于Ubuntu强调提供最新的软件版本，因此其稳定性可能相对较差。这可能导致在某些生产服务器环境下不太适合运行LLM。 
        - **LTS支持周期有限**：虽然Ubuntu的长期支持版本（LTS）提供了较长时间的支持周期，但相对某些其他发行版来说仍然较短。这就需要用户在支持周期结束后进行操作系统的升级或迁移。 

#### 8.3 搭建环境所需组件

以下是搭建环境需要安装的组件。

1. **CUDA**

CUDA（Compute Unified Device Architecture）是由显卡厂商NVIDIA推出的通用并行计算架构。它使得开发人员能够使用NVIDIA的图形处理器（GPU）来解决复杂的计算问题，从而实现计算性能的显著提升。

CUDA架构充分利用了GPU的并行计算引擎，让开发人员能够编写出高效且可扩展的并行计算程序。在CUDA内部编程模型中，CPU被视为主机（Host），而GPU则被视为设备（Device）。开发人员可以使用C/C++/C++11等语言为CUDA架构编写程序，并通过NVIDIA提供的CUDA工具集进行编译和优化。

CUDA的应用范围非常广泛，它可以用于加速各种类型的计算任务，包括图像处理、物理模拟、深度学习、科学计算等。通过利用GPU的并行计算能力，CUDA可以显著提高这些计算任务的执行效率，使得原本需要花费大量时间的计算过程可以快速完成。

总的来说，CUDA是一种强大的并行计算平台和编程模型，使得开发人员能够充分利用GPU的并行计算能力来解决复杂的计算问题，从而实现计算性能的显著提升。

2. **cuDNN**

cuDNN（cuDA Deep Neural Network library）是一个用于深度神经网络（DNN）的GPU加速库。它由NVIDIA公司开发并且是专门为其GPU设计的。cuDNN为标准例程（如向前和向后卷积、池化、规范化和激活层等）提供了高度优化的实现，从而在深度神经网络训练和推理过程中显著提升性能。

几乎全球范围内的深度学习研究人员和框架开发人员都依赖cuDNN来实现高性能的GPU加速功能，其使得他们可以专注于训练神经网络和开发软件应用程序，而不需要在底层的GPU性能调优上花费大量时间。cuDNN支持广泛使用的深度学习框架，如Caffe2、Chainer、Keras、MATLAB、MxNet、PyTorch和TensorFlow等。

总的来说，cuDNN是NVIDIA CUDA技术生态中的一个重要组成部分，为深度神经网络的训练和推理提供了高效、便捷的解决方案。通过cuDNN，开发人员能够充分利用NVIDIA GPU的强大计算能力，加速深度神经网络训练和推理过程，进而推动各种应用领域的发展和创新。 

3. **Anaconda**

Anaconda是一个开源的Python发行版，包含了conda、Python，以及众多与科学计算和数据分析相关的包。Anaconda通过conda包管理系统，提供了包管理与环境管理的功能，可以方便地解决多版本Python并存、切换，以及各种第三方包的安装问题。此外，Anaconda还预装了大量的常用数据分析和机器学习库，使得用户可以快速搭建自己的Python数据科学环境。无论是初学者还是专业人士，都可以通过Anaconda轻松进行Python的科学计算和数据分析工作。 

4. **PyTorch**

PyTorch是一个由Facebook人工智能研究院（FAIR）研发的神经网络框架，专门针对GPU加速的深度神经网络进行编程。

PyTorch的设计理念是追求最少的封装，尽量避免重复，因此具有简洁、灵活和易于调试的特点。PyTorch主推的特性之一是支持Python。在运行时，PyTorch可以生成动态计算图，开发人员就可以在堆栈跟踪中看到是哪一行代码导致了错误，这使得调试过程更加便捷。

PyTorch支持广泛的深度学习框架和库，如Caffe2、Chainer、Keras、MATLAB、MxNet和TensorFlow等，因此可以方便地与其他框架进行集成和交互。此外，PyTorch还支持分布式训练，可以实现可伸缩的分布式训练和性能优化，在研究和生产环境中都具有广泛的应用。

总的来说，PyTorch是一个功能强大、灵活易用的神经网络框架，适用于各种深度学习应用场景。它支持GPU加速计算，具有动态计算图和高效的分布式训练功能，为研究人员和开发人员提供了便捷的工具和平台。 

5. **VSCode**

VSCode是由微软公司推出的一款免费、开源的源代码编辑器。这款编辑器支持多种编程语言，包括但不限于JavaScript、TypeScript、Python、PHP、C#、C++、Go等，提供了强大的编辑和调试功能。

VSCode的设计注重用户体验和扩展性，提供了丰富的插件生态系统，用户可以通过安装扩展来增强其功能。它集成了一款现代编辑器应该具备的所有特性，包括语法高亮、可定制的热键绑定、括号匹配及代码片段收集等。同时，VSCode内置了Git版本控制功能，允许用户直接进行提交（Commit）、拉取（Push）、推送（Pull）等操作。此外，它还支持对GitHub、Bitbucket等远程仓库的集成，从而可以让开发人员更加方便地管理代码。

VSCode的界面简单明了，功能强大，支持跨平台（包括macOS、Windows、Linux等多种操作系统）运行，保证了开发人员的工作效率和软件的可移植性。

总的来说，VSCode是一款轻量级且功能强大的源代码编辑器，适合初学者、专业人士等各种编程人员使用。 



#### 8.4 LLM常用知识介绍

##### 8.4.1 分类

1. **按照开源、闭源分类**
    - **闭源**：ChatGPT、文心一言。
    - **开源**：Llama、通义千问。

2. **按照国内、国外分类**
    - **国内**：文心一言、通义千问、ChatGLM。
    - **国外**：ChatGPT、Llama、BLOOM。

##### 8.4.2 参数大小**
- 通义千问：72B、14B、7B、4B（建议）、1.8B（建议）、0.5B（建议）。
- ChatGLM：6B。
- Llama：7B、13B、33B和65B。

##### 8.4.3 训练过程**
ChatGPT的训练过程，一般分成预训练、Chat两类模式。

##### 8.4.4 模型类型**

所有LLM几乎都是基于Transformer架构开发的，通常根据Transformer在自然语言处理任务中的应用，可以将其分为以下3类。

1. **Decoder - only**

这类模型主要用于执行生成任务，如文本生成、机器翻译等。

代表模型：GPT系列（包括ChatGPT）。它们主要用于文本生成和对话系统。 

2. **Encoder - only**

这类模型通常用于执行理解任务，如文本分类、实体识别等。

代表模型：BERT（Bidirectional Encoder Representations from Transformers）。它是一个强大的预训练模型，用于执行各种自然语言处理任务，如问答、文本分类等。 

3. **Encoder - Decoder**

这类模型结合了编码器和解码器的功能，适用于既需要理解输入又需要生成输出的任务，如机器翻译、问答等。

代表模型：Transformer本身就是一个Encoder - Decoder结构，用于执行序列到序列的学习任务。ChatGLM是一个基于Transformer的Encoder - Decoder结构的模型，用于设计对话任务。不过，值得注意的是，ChatGLM并不是一个被广泛认知的模型名称，而是某个特定项目或公司的模型名称。



总的来说，Transformer架构通过其强大的自注意力机制和并行计算能力，显著提升了自然语言处理任务的性能。不同类型的Transformer模型针对不同的自然语言处理任务进行了优化和调整。

##### 8.4.5 模型开发框架**
模型开发框架主要有三种：PyTorch、TensorFlow和PaddlePaddle。

##### 8.4.6 量化大小**

在深度学习和机器学习领域中，模型量化是一种缩小模型和降低推理延迟的技术，同时尽量保持模型的准确性。量化主要是将模型的权重和激活值从32位浮点数（Float32）转换为较低精度[如8位（Int8）或4位（Int4）]的整数。


1. **Int8量化**

在Int8量化中，模型的权重和激活值被转换为8位整数。这大大缩小了模型和减少了内存占用量，同时加快了推理速度，因为整数通常比浮点数的运算速度更快。

Int8量化在保持较高精度的同时，显著降低了模型的存储和计算需求。这是目前应用十分广泛的量化方法之一。 

2. **Int4量化**

在Int4量化中，模型的权重和激活值被进一步压缩为4位整数。这种量化方法可以实现更高的压缩比和更快的推理速度，但可能会牺牲一定的模型精度。

由于Int4量化的表示范围有限，因此在进行这种量化时需要特别小心，以确保模型的准确性不会受到严重影响。 



#### 8.5 量化技术

模型量化技术主要分为以下3种。

1. **AWQ**

AWQ用于缩小神经网络模型和降低计算复杂度。

它的核心思想是仅保护模型中的一小部分显著权重，通常是1%，其余99%的权重会被量化，从而大大减少量化误差。这种技术旨在确保量化过程不会对模型的性能产生太大影响。

通过这种技术，可以在降低模型存储和计算需求的同时，尽可能地保持模型的原始性能。 

2. **GPTQ**

GPTQ是Google AI提出的一种基于Group量化和OBQ（Optimal Brain Quantization或类似术语的缩写）方法的量化技术。

Group量化是一种通过将权重分为多个子矩阵来进行量化的技术，有助于缩小模型和降低计算复杂度。

OBQ是一种优化量化过程的方法，旨在进一步提升量化后模型的性能。

然而，请注意，GPTQ也可能与Generative Pre - trained Transformer（如GPT系列模型）有关，但在量化上下文中，它更可能指的是量化技术。 

3. **GGUF**

GGUF是由Llama.cpp团队引入的一种技术，用于替代不再支持的GGML格式。

它旨在提供一种标准化的方式来表示和交换量化后的模型数据。

GGUF支持使用多种量化方法（如Q2_K、Q3_K_S、Q4_K_M等）来优化模型文件的大小和性能。它还提供了不同位数（如2位、3位、4位等）的模型，以便在CPU+GPU环境下进行推理。这种格式具有良好的兼容性，支持多个第三方用户图形界面和库。 



#### 8.6 模型选择

##### 8.6.1 通义千问**

通义千问是由阿里云推出的一个LLM，具有多轮对话、文案创作、逻辑推理、多模态理解及多语言支持等多种强大的功能。

- **参数大小**：7B（试过了，很卡）、4B（建议）、1.8B（建议）、0.5B（建议）。

- **量化**：不建议使用量化技术，以免影响模型精度。



##### 8.6.2 ChatGLM**

ChatGLM是一个基于千亿基座模型GLM - 130B开发的对话机器人，由清华大学KEG实验室和智谱AI公司共同研发。它支持中英双语，并具有问答、多轮对话和代码生成等功能。ChatGLM目前有两个版本，分别是具有千亿参数的ChatGLM（内测版）和具有6B参数的ChatGLM - 6B（开源版）。

ChatGLM - 6B在2023年3月14日正式开源，用户可以在消费级的显卡上进行本地部署。这个模型在多个自然语言处理任务上表现出色，经过约1TB标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术，已经能够生成非常符合人类偏好的答案。

- **参数大小**：6B。

- **量化**：不建议使用量化技术，以免影响模型精度。



##### 8.6.3 Llama**


Llama（Large Language Model Meta AI）是Meta人工智能研究院研发的AI LLM，旨在帮助研究人员和工程师探索AI应用和相关功能。该模型在生成文本、对话、总结书面材料、证明数学定理或预测蛋白质结构等更复杂的任务方面“有很广泛的前景”。

Llama模型首次发布于2023年2月。与其他LLM类似，Llama在大量的文本数据上进行训练，从而学习到广泛的语言知识和模式。这使得它可以根据用户提供的输入，生成连贯、有逻辑的文本输出。

- **参数大小**：7B、13B、33B、65B。

- **量化**：不建议使用量化技术，以免影响模型精度。



#### 8.7 模型应用实现方式

从模型应用实现方式的难易程度来分类，主要分为三种，从易到难分别为Chat、RAG、高效微调。

1. **Chat**

Chat是一种通过prompt来实现模型的应用，以聊天的方式解决问题，需要用到的技术就是prompt。 

2. **RAG**

RAG是一种结合了信息检索和文本生成技术的先进方法。在RAG系统中，当用户输入一个问题或进行查询时，系统首先会从一个大型的知识库或文档集中检索相关的信息或


文档内容主要围绕LLM（大语言模型）本地部署与应用展开，以下是后续内容梳理：
### 8.7 模型应用实现方式（续）
#### 8.7.2 RAG（续）
文档提到在RAG系统中，当用户输入问题或查询时，系统首先从大型知识库或文档集中检索相关信息或文档，然后利用这些信息辅助生成针对用户输入的答案。好处是能结合外部知识源丰富模型输出，使答案更准确、具体、有用。例如在问答系统中，模型可从知识库检索文档生成准确答案。RAG主要用到prompt + 知识库（一般是向量数据库） + 向量化方法（如BERT、ERNIE等自然语言处理技术 ）。 
#### 8.7.3 高效微调
高效微调指对大型预训练模型进行快速、有效的调整，使其适应特定任务或领域。因LLM参数众多，全面微调耗时长、资源多，所以研究人员开发系列高效微调技术以在有限资源和时间内优化模型。其中，LoRA（Low - Rank Adaptation，低秩自适应）是具代表性的高效微调方法，它通过向模型的权重矩阵添加低秩更新来实现微调，显著减少需调整的参数量，降低微调成本和复杂度。开发人员需准备少量高质量标注数据及充足算力（如A100、V100 ）。高效微调主要用到LoRA + 高质量标注数据 + 算力。 


