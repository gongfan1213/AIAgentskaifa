
![image](https://github.com/user-attachments/assets/9f466a38-e147-447c-a26b-0f202a5f63a4)


单击“Test Model”按钮，如果显示图8-12所示的界面，则说明LLM已配置成功。


![image](https://github.com/user-attachments/assets/b7382c6d-6bf8-44a6-aba3-2227367f926d)


### 8.9.8 把Agent中的模型置换成通义千问
选择界面左侧的“Agents”选项，并选择要修改的Agent，把“Model”换成8.9.7节中配置的模型（通义千问），如图8-13所示。


![image](https://github.com/user-attachments/assets/8a6e2e53-6252-4be3-ad55-e2c57abdd663)


### 8.9.9 运行并测试Agent

选择AutoGen Studio界面中的“Playground”选项卡，在此界面中创建会话，如图8-14所示。


![image](https://github.com/user-attachments/assets/602807ba-a236-4f28-92bb-de84172a7e53)


单击“+New”按钮，并选择“Default Agent Workflow”选项，如图8-15所示。


![image](https://github.com/user-attachments/assets/064e3263-f249-4ee3-bb36-17f31bf20529)


在图8-16所示的输入框中随便输入问题，如果有结果返回，则说明LLM已部署成功。


![image](https://github.com/user-attachments/assets/138d06cb-f308-4aba-aad2-686cab7abbf3)


通过本地部署LLM，用户不仅能享受到更快速、更灵活的模型响应，同时能确保数据的安全性和用户隐私得到保护。此外，本地部署也能够使用户更深入地了解和定制模型的行为，从而满足特定的业务需求或研究目标。无论是在提升用户体验、优化业务流程，还是在推动自然语言处理技术的发展上，本地部署LLM都展示出了巨大的潜力和价值。 
