第10章 PEFT微调实战——打造医疗领域LLM

（5）读入数据。

根据指定的数据路径加载数据集，通常使用load_dataset函数：
```python
if data_path.endswith(".json") or data_path.endswith(".jsonl"):
    data = load_dataset("json", data_files=data_path)
else:
    data = load_dataset(data_path)
```

（6）开始微调。

使用Trainer对象开始微调：
```python
trainer = transformers.Trainer
```

（7）模型保存。

在微调结束后，将微调后的模型保存到指定路径中：
```python
model.save_pretrained(output_dir)
```
通过以上流程，即可完成对预训练模型的微调，并将微调后的模型保存到指定路径中，以供后续使用。

# 10.3.7 运行模型微调代码

以下是运行模型微调代码的详细步骤。

在PyCharm中打开“finetune.py”文件。在代码编辑界面中右击该文件，弹出快捷菜单，选择“Run 'finetune'”命令，如图10 - 42所示。


![image](https://github.com/user-attachments/assets/18f86554-e13e-4768-ba90-769a6f99ec24)



| Show Context Actions | Alt+Enter |
| --- | --- |
| Cut | Ctrl+X |
| Copy / Paste Special |  |
| Column Selection Mode | Alt+Shift+A |
| Find Usages | Alt+F7 |
| Refactor |  |
| Folding |  |
| Go To |  |
| Generate... | Alt+Insert |
| **Run 'finetune'** | Ctrl+Shift+F10 |
| Debug 'finetune' |  |
| Modify Run Configuration... |  |
| Open In |  |
| Local History |  |
| Execute Line in Python Console | Alt+Shift+E |
| Run File in Python Console |  |
| Compare with Clipboard |  |
| Create Git... |  |

图10 - 42

若在PyCharm输出窗口中显示图10 - 43所示的信息，则表示微调开始执行。


![image](https://github.com/user-attachments/assets/f4d54b09-b408-46c6-8665-fc2f750a1b61)


| finetune |  |  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
|  | 40/63 | [00:20<00:37, 1.70s/it] |  |  |  |  |  |  |  |
| 65% | 41/63 | [00:20<00:37, 1.70s/it] |  |  |  |  |  |  |  |
| 67% | 42/63 | [00:21<00:31, 1.51s/it] |  |  |  |  |  |  |  |
| 68% | 43/63 | [00:21<00:22, 1.11s/it] |  |  |  |  |  |  |  |
| 70% | 44/63 | [00:22<00:16, 1.16it/s] |  |  |  |  |  |  |  |
| 71% | 45/63 | [00:22<00:11, 1.52it/s] |  |  |  |  |  |  |  |
| 73% | 46/63 | [00:22<00:08, 1.94it/s] |  |  |  |  |  |  |  |
| 75% | 47/63 | [00:22<00:06, 2.32it/s] |  |  |  |  |  |  |  |
| 76% | 48/63 | [00:22<00:05, 2.89it/s] |  |  |  |  |  |  |  |
| 78% | 49/63 | [00:22<00:04, 3.58it/s] |  |  |  |  |  |  |  |
| 79% | 50/63 | [00:23<00:03, 4.08it/s] |  |  |  |  |  |  |  |
| 81% | 51/63 | [00:23<00:02, 4.55it/s] |  |  |  |  |  |  |  |
| 83% | 52/63 | [00:23<00:02, 5.08it/s] |  |  |  |  |  |  |  |
| 84% | 53/63 | [00:23<00:01, 5.42it/s] |  |  |  |  |  |  |  |
| 86% | 54/63 | [00:23<00:01, 5.99it/s] |  |  |  |  |  |  |  |
| 87% | 55/63 | [00:23<00:01, 6.27it/s] |  |  |  |  |  |  |  |
| 89% | 56/63 | [00:24<00:01, 6.36it/s] |  |  |  |  |  |  |  |

图10 - 43

# 10.4 模型推理验证

完成微调后，就获得了经过微调的模型，我们可以通过推理代码“infer.py”来验证微调效果。以下是推理部分的主要代码和步骤。

1. 准备模型文件

将微调后生成的模型文件“adapter_config.json”和“adapter_model.bin”复制到“lora - agent - med”项目文件夹中。

2. 配置参数

配置相应的参数，如图10 - 44所示。


| **Run/Debug Configurations** |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
|  | Python | infer |  |  |  |  |
|  |  |  |  |  |  |  |
|  |  | Name: | infer |  | Allow parallel run | Store as project file |
|  |  | **Configuration Logs** |  |  |  |  |
|  |  | Script path: | D:\paper\AI_Agent_Med_Chinese\main\infer.py |  |  |  |
|  |  | Parameters: | --base_model Qwen/Qwen-1.5 - 0.58 --template chinese_med --use_lora --lora_weights ./lora --instruct_dir ./data/infer.json --model_output_dir med_template |  |  |  |
|  |  | **Environment** |  |  |  |  |
|  |  | Environment variables: |  |  |  |  |
|  |  | Python interpreter: |  |  |  |  |
|  |  | Interpreter options: |  |  |  |  |
|  |  | Working directory: |  |  |  |  |
|  |  | Add content roots to |  |  |  |  |
|  |  | Add source roots to |  |  |  |  |
|  |  | **Execution** |  |  |  |  |
|  |  | Emulate terminal in output console |  |  |  |  |
|  |  | Run with Python Console |  |  |  |  |
|  |  | Redirect input from: |  |  |  |  |
|  |  | **Before launch** |  |  |  |  |
|  |  |  | OK | Cancel | Apply |  |

图10 - 44


![image](https://github.com/user-attachments/assets/ea324ac8-eada-462a-9a09-90026f88c351)


3. 引入分词器和模型

引入所需的分词器和模型，以便后续使用：
```python
from transformers import Qwen2Tokenizer, Qwen2ForCausalLM
```
4. 加载基础模型
加载基础模型，示例代码如下：
```python
model = Qwen2ForCausalLM.from_pretrained(
    base_model,
    load_in_8bit=load_8bit,
    #torch_dtype=torch.float16,
    torch_dtype=torch.float32,
    device_map="auto",
)
```
5. 加载分词器

加载分词器，示例代码如下：
```python
tokenizer = Qwen2Tokenizer.from_pretrained(base_model)
```
6. 加载微调后的模型权重


如果使用了lora（局部敏感退化），则需加载微调后的模型权重，示例代码如下：
```python
if use_lora:
    print(f"using lora {lora_weights}")
    model = PeftModel.from_pretrained(
        model,
        lora_weights,
        torch_dtype=torch.float32,
    )
```
7. 运行推理代码


在代码编辑界面中右击，在弹出的快捷菜单中选择“Run infer”命令，即可运行代码。运行结果如图10 - 45所示。

| Run: infer |  |  |  |
| --- | --- | --- | --- |
|  | ###Instruction### |  |  |
|  | 小王被确诊为肝炎双重感染，最可能的并发症是什么？ |  |  |
|  | ###golden output### |  |  |
|  | 最可能的并发症是肝癌和肝硬化。 |  |  |
|  | ###model output### |  |  |
|  | A. 肝硬化 |  |  |
|  | B. 肝癌 |  |  |
|  | C. 肝脓肿 |  |  |
|  | D. 肝肾综合征 |  |  |
|  | E. 肝功能衰竭 |  |  |
|  | 答案: A|<endoftext>|  |
|  | ###infering### |  |  |
|  | ###Instruction### |  |  |
|  | 麻风病和儿童哮喘的病因是否一致？ |  |  |
|  | ###golden output### |  |  |
|  | 不一致，麻风病的病因是麻风分枝杆菌，而儿童哮喘的病因是气候、药物、吸入过敏原等。 |  |  |
|  | ###model output### |  |  |
|  | 麻风病和儿童哮喘的病因不一致。麻风病是由麻风分枝杆菌引起的一种慢性接触性传染病，儿童哮喘是由过敏性鼻炎引起的一种慢性呼吸道疾病。 |  |  |

图10 - 45

![image](https://github.com/user-attachments/assets/f0426251-fcb6-45f5-8aca-a6afd4e94673)


通过以上步骤，就完成了模型的微调和推理。训练后的模型输出风格更接近训练数据。 
